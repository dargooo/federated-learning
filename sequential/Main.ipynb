{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "incident-miracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime\n",
    "from copy import deepcopy\n",
    "from queue import Queue\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('../')\n",
    "import models\n",
    "from models import CF10Net\n",
    "from devices import *\n",
    "from data_utils import split_data, CustomSubset\n",
    "from server import *\n",
    "from client import *\n",
    "from leader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "tired-elite",
   "metadata": {},
   "outputs": [],
   "source": [
    "def server_prepare_data():\n",
    "    print(\"--> Preparing data...\")\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(root='~/data', train=False, download=True, transform=transform)\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=1)\n",
    "\n",
    "    test_idcs = np.random.permutation(len(testset))\n",
    "\n",
    "    return CustomSubset(testset, test_idcs, transforms.Compose([transforms.ToTensor()])), testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "palestinian-closure",
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_prepare_data(N_CLIENTS):\n",
    "    print(\"--> Preparing and splitting data...\")\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(root='~/data', train=True, download=True, transform=transform)\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=0)\n",
    "\n",
    "    train_idcs = np.random.permutation(len(trainset))\n",
    "\n",
    "    client_idcs = np.arange(0, len(trainset)).reshape(N_CLIENTS, int(len(trainset) / N_CLIENTS))\n",
    "\n",
    "    train_labels = []\n",
    "    for idc in client_idcs:\n",
    "        for idcc in idc:\n",
    "            train_labels.append(trainset[idcc][1])\n",
    "    train_labels = np.array(train_labels)\n",
    "    DIRICHLET_ALPHA = 10\n",
    "    client_idcs = split_data(train_idcs, train_labels, alpha=DIRICHLET_ALPHA, n_clients=N_CLIENTS)\n",
    "\n",
    "    return [CustomSubset(trainset, idcs) for idcs in client_idcs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "theoretical-lewis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Preparing data...\n",
      "Files already downloaded and verified\n",
      "--> Preparing and splitting data...\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "N_LEADERS = 1\n",
    "N_CLIENTS = 4\n",
    "\n",
    "# Server\n",
    "test_data, testloader = server_prepare_data()\n",
    "server = Server(CF10Net, test_data, testloader)\n",
    "\n",
    "# Client\n",
    "client_list = []\n",
    "client_datas = client_prepare_data(N_CLIENTS)\n",
    "for i, data in enumerate(client_datas):\n",
    "    leader_id = -1\n",
    "    if N_LEADERS > 0:\n",
    "        group_size = int(N_CLIENTS / N_LEADERS)\n",
    "        leader_id = int(i / group_size)\n",
    "    client_list.append(Client(CF10Net, lambda x : torch.optim.SGD(x, lr=0.001, momentum=0.9), data, id=i))\n",
    "    \n",
    "# Leader\n",
    "leader_list = []\n",
    "for i in range(N_LEADERS):\n",
    "    leader = Leader(CF10Net, i)\n",
    "    for j in range(group_size * i, group_size * (i+1)):\n",
    "        leader.client_list.append(client_list[j])\n",
    "    leader_list.append(leader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "divine-venture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Server - eval] rd = 1, acc = [ 0.1 ]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggressive-senior",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
